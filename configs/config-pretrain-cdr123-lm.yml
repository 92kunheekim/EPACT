task: cdr123-lm

training:
  gpu_device: 0
  batch_size: 512
  num_workers: 4
  seed: 42
  lr: 1.e-4
  weight_decay: 1.e-2
  max_epochs: 100
  warm_epochs: 10
  patience: 20
  lr_scheduler: cosine
  lr_decay_steps: 100
  lr_decay_rate: 0.5
  lr_decay_min_lr: 1.e-6
  log_dir: logs/pretrained-cdr123-lm/

model:
  num_layers: 6
  embed_dim: 512
  num_heads: 4
  max_seq_length: 26
  attn_dropout: 0.05

data: 
  use_cdr123: True
  data_path: data/pretrained/combined_paired_pretrain_data.csv
  max_cdr3_len: 25
